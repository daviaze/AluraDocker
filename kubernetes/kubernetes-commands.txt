*pods -  Funciona como uma capsula com um ip designado, em que irá conter um ou mais containeres dentro da mesma;
*kubectl - Gerenciador dos pods do sistema de clusters do kubernetes -> É ele quem vai enviar as requisições para criar, atualizar, ler,
e remover os pods;


kubectl get nodes - Retorna todos os nós presentes no cluster;
kubectl get pods - Retorna todos os pods;
kubectl get svc - Retorna todos os serviços;
kubectl get deployments - Retorna todos os deployments;
kubectl get rs - Retorna todos os replicaSets;
kubectp get pv - Retorna todos os PersistentVolums;
kubectl get pvc - Retorna todos os PersistentVolumsClaims;
kubectl get sc - Retorna todos os StorageClass;
kubectl get hpa - Retorna todos os Horizontal Pod AutoScale;
kubectl run [nome do pod que deseja criar] --image=[imagem:versao] - Cria um pod com uma imagem para um container
que será criado dentro do pod;
kubectl describe pod [nome do pod] - Retorna informações sobre aquele pod;
kubectl edit pod [nome do pod] - Para edição de um pod;
kubectl apply -f .\primeiro-pod.yaml - Cria ou Atualiza o pod de forma declarativa com base no arquivo yaml;
kubectl exec -it [nome do pod] -- bash - Executa comando para entrar dentro de container dentro do pod;

*Serviço ClusterIP -> utilizado para estabelecer conexão entre os nós do cluster;
*Serviço NodePort -> utilizado para estabelecer conexão para fora do cluster mas também se
comunica internamente entre os nós do cluster;
*Serviço LoadBalancer -> parecido com o ClusterIP, abre comunicação para o mundo externo,
por exemplo: para abrir conexão com um provedor de nuvem como google cloud, azure, aws, etc.

Escopo genérico de criação de um pod:
apiVersion: v1
kind: Pod -> Tipo de recurso
metadata:
  name: pod-1 -> Nome do recurso
spec:
  containers:
    - name: container-pod-1 -> Nome do container
      image: nginx:latest
      ports:
        - containerPort: 80 -> Expoe nessa porta


Escopo genérico de criação de um serviço ClusterIP:
apiVersion: v1
kind: Service -> Tipo de recurso
metadata:
  name: svc-pod-2 -> Nome do recurso
spec:
  type: ClusterIP -> Tipo do recurso
  selector:
    app: segundo-pod -> Seleciona somente os pods que possuem esta label
  ports:
    - port: 9000 -> Porta em que ele vai expor
      targetPort: 80 -> Porta em que ele vai apontar no pod

Escopo genérico de criação de um serviço NodePort:
apiVersion: v1
kind: Service
metadata:
  name: svc-pod-1
spec:
  type: NodePort
  selector:
    app: primeiro-pod
  ports:
    - port: 8000
      targetPort: 80
      NodePort: 30000 -> Porta em que o pod irá expor para fora do cluster

Escopo genérido de criação de um serviço LoadBalancer:
apiVersion: v1
kind: Service
metadata:
  name: svc-pod-1-loadbalancer
spec:
  type: LoadBalancer
  selector:
    app: primeiro-pod
  ports:
    - port: 80
      nodePort: 30000

Escopo para criar variáveis de ambiente em um pod (geralmente necessário em banco de dados):
apiVersion: v1
kind: Pod -> Tipo de recurso
metadata:
  name: pod-1 -> Nome do recurso
spec:
  containers:
    - name: container-pod-1 -> Nome do container
      image: nginx:latest
      ports:
        - containerPort: 80 -> Expoe nessa porta
      env:
        - name: "MYSQL_ROOT_PASSWORD"
          value: "123456"
        - name: "MYSQL_DATABASE"
          value: "empresa

OBS: Apesar do exemplo acima aplicado para criar variáveis de ambiente, é de boa prática criar um ConfigMap, que armazenará todas essas
variáveis, para garantir o baixo acoplamento, e reutilização das variáveis.

Escopo para criar o ConfigMap:
apiVersion: v1
kind: ConfigMap
metadata:
  name: configmap
data:
  MYSQL_ROOT_PASSWORD: 123456
  MYSQL_DATABASE: empresa

Segue o exemplo abaixo para puxar as variáveis de ambiente de um configMap:
apiVersion: v1
kind: Pod -> Tipo de recurso
metadata:
  name: pod-1 -> Nome do recurso
spec:
  containers:
    - name: container-pod-1 -> Nome do container
      image: nginx:latest
      ports:
        - containerPort: 80 -> Expoe nessa porta
      envFrom:
        - configMapRef:
            name: configmap -> Faz a referência ao configMap criado anteriormente

ReplicaSets -> Recurso de disponibilidade e recursividade, utilizado para sempre que um pod caia ou pare de funcionar, automaticamente o kubernetes
irá subistitui-lo por uma cópia do mesmo;

Segue o exemplo abaixo para criação de um ReplicaSet:
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: portal-noticias-replicaset
spec:
  template:
    metadata:
      name: portal-noticias
      labels:
        app: portal-noticias
    spec:
      containers:
        - name: portal-noticias-container
          image: aluracursos/portal-noticias:1
          ports:
            - containerPort: 80
          envFrom:
            - configMapRef:
                name: portal-configmap
  replicas: 3 -> irá criar 3 réplicas do pod
  selector:
    matchLabels:
      app: portal-noticias -> irá selecionar os pods cujo label seja igual

Deployment -> Tem o mesmo objetivo que o ReplicaSets, porém com recursos de versionamento de imagem, controle, etc; 
OBS: O deployment implicitamente também cria replicaSets;

Segue o exemplo abaixo para criação de um Deployment:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3 -> irá criar 3 réplicas do pod
  template:
    metadata:
      name: nginx-pod
      labels:
        app: nginx-pod
    spec:
      containers:
        - name: nginx-container
          image: nginx-latest
          ports:
            - containerPort: 80
  selector:
    matchLabels:
      app: nginx-pod -> irá selecionar os pods cujo label seja igual

Comandos de versionamento para deployments:

kubectl rollout history deployment/nginx-deployment -> Retorna o histórico de versionamento
kubectl apply -f nginx-deployment.yaml --record -> A flag --record grava o deploy no versionamento
kubectl annotate deployment nginx-deployment kubernetes.io/change-cause="Definindo outra versão da imagem" -> Altera a informação da versão atual
kubectl rollout undo deployment nginx-deployment --to-revision=2

Persistencia de dados:

Volumes com hostPath são dependentes de pods, a partir do momento que um pod é encerrado, o volume também é.
Volumes com hostPath são vinculados entre um diretório host e um diretório de dentro do container.

apiVersion: v1
kind: Pod
metadata:
  name: um-pod-qualquer
spec:
  containers:
    - name: nginx-container
      image: nginx:latest
      volumeMounts:
        - mountPath: /pasta-de-arquivos
          name: volume-pod
  volumes:
    - name: volume-pod
      hostPath:
        path: /C/Users/Davi/Desktop/uma-pasta-no-host
        type: Directory

**Existem outros tipos de persistencia, como por exemplo o PersistentVolume junto com PersistentVolumeClaim,
que são muito utilizados na criação de volumes em plataformas cloud, fazendo com que o volume seja independente
do pod, pois é criado um disco, um pv, um pvc para acessar um pv que acessa um disco. No entanto, não existem somente
esses meios de criação e manipulação de volumes, existem vastas opções, basta seguir a documentação.
Uma forma de criar esses persists volums é através de uma storageClass, que de forma dinâmica possibilita
pods criarem PVs e discos de forma dinâmica, conforme a necessidade. Pode-se criar também volums através de 
StateFullSet, que funciona parecido como um deployment, porém também de forma dinâmica, com uso de storage
class e um pvc, ele gera pvs;

Link da documentação: https://kubernetes.io/pt-br/docs/concepts/storage/persistent-volumes/
Video auxiliar: https://www.youtube.com/watch?v=_WxMQRFmXd4 


Liveness Probes:

É utilizado para manter a aplicação saudável, realizando testes periódicos, sendo que caso seja detectado
algum erro, o pod será reiniciado. Essa configuração poderá ser adicionada dentro do escopo de criação
de um container dentro de um pod.

Ex:

livenessProbe:
  httpGet:
    path: / -> caminho da página http
    port: 80 -> porta que está rodando a aplicação
  periodSeconds: 10 -> o teste será executado a cada 10s
  failureThreshold: 3 -> a aplicação só poderá suportar 3 falhas antes do reinicio
  initialDelaySeconds: 20 -> os testes começaram 20s a partir do container subir

0BS: O livenessProbe indicará falha caso o código de retorno seja menor que 200 ou maior/igual a 400.

Readiness Probes:

É utilizado para informar ao kubernetes que aquele container que acabou de ser reiniciado já está pronto
para receber requisicoes novamente, pois cada container demora um período até que esteja pronto, pois precisam
carregar suas dependencias, etc.

Ex:

readinessProbe:
  httpGet:
    path: / -> caminho da página http
    port: 80 -> porta que está rodando a aplicação
  periodSeconds: 10 -> o teste será executado a cada 10s
  failureThreshold: 5 -> a aplicação irá verificar n vezes se o container está pronto, a partir da 4º tentativa
  as requisicoes serão enviadas mesmo assim;
  initialDelaySeconds: 3 -> os testes começaram 3s a partir do container subir


Escalabilidade com Horizontal Pod AutoScale:

É utilizado para deixar a aplicação escalável conforme a necessidade de processamento. Esta configuração
pode ser feita diretamente na criação do container de um pod, também criar um hpa, e configurar um servidor
de métricas, vulgo components.yaml;

Ex:

resources:
  requests:
    cpu: 10m -> Exige 10 milicores de CPU para funcionar

Ex de Hpa:
apiVersion: autoscalling/v2beta2
kind: HorizontalPodAutoScaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVerison: apps/v1
    kind: Deployment
    name: nginx-deployment
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu -> as metricas vão se basear na CPU do sistema
        target:
          type: Utilization -> baseado na utilizacao
          averageUtilization: 50 -> o autoscale vai acontecer quanto a utilização ultrapassar 50% dos milicores de CPU
          necessários para o container funcionar
